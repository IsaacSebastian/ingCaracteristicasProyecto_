{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are in the preferable working directory, I'll explore each data file's variables in order to figure out how to join each dataframe into a big dataset. Let's begin chronologically:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2000-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/26l5nfs54r94_664jm4k6zvr0000gn/T/ipykernel_9866/36002156.py:4: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_2020=pd.read_csv(f\"{data_path}/2020.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_2000=pd.read_csv(f\"{data_path}/2000.csv\")\n",
    "df_2005=pd.read_csv(f\"{data_path}/2005.csv\")\n",
    "df_2010=pd.read_csv(f\"{data_path}/2010.csv\")\n",
    "df_2020=pd.read_csv(f\"{data_path}/2020.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think it will be a good idea to split the population columns into categories. For example, the 'Población de 15 años y más' column will be abreviated as 'POB_15+', and each description will be abreviated as well.\n",
    "\n",
    "I'll begin with abreviating the first part of the population columns.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I need to find a good use of regular expressions in order to speed things up. I want for the next columns to have the name structure: \"POB_[age_range]_[category]\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def population(column_name):\n",
    "    match=re.search(\"Población\",column_name)\n",
    "    if match:\n",
    "        sex=re.search(\"femenina|masculina\",column_name)\n",
    "        if sex:\n",
    "            letter=str.upper(sex.group()[0])\n",
    "            return f\"POB {letter}\"\n",
    "        return \"POB\"\n",
    "    \n",
    "def age_range(column_name):\n",
    "    \"\"\" \n",
    "    \n",
    "    Takes a column name as an input and spits out the age range the input contains\n",
    "    \n",
    "    \"\"\"\n",
    "    # Case for specified age range:\n",
    "    age_range_pattern=r'\\d+ a \\d+' \n",
    "    match=re.search(age_range_pattern,column_name)\n",
    "    if match:\n",
    "        age_range=match.group()\n",
    "        #age_range=str.replace(age_range,\" \",\"_\")\n",
    "        return age_range\n",
    "    \n",
    "    # Case for ambiguos age range:\n",
    "    ambiguos_age_range_pattern_1=r\"\\d+ años y más\"\n",
    "    match=re.search(ambiguos_age_range_pattern_1,column_name)\n",
    "    if match:\n",
    "        text=match.group(0)\n",
    "        age_range=f\"{re.findall(r'\\d+',column_name)[0]}+\"\n",
    "        return age_range\n",
    "    \n",
    "    ambiguos_age_range_pattern_2=r\"\\d+ años\"\n",
    "    match=re.search(ambiguos_age_range_pattern_2,column_name)\n",
    "    if match:\n",
    "        text=match.group(0)\n",
    "        age_range=f\"{re.findall(r'\\d+',column_name)[0]}+\"\n",
    "        return age_range   \n",
    "    \n",
    "    \n",
    "def category(column_name):\n",
    "    \"\"\" \n",
    "    \n",
    "    Takes a column name as an input and spits out the category wanted depending on what the input contains\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    categories={\n",
    "         #Education\n",
    "        \"que no asiste a la escuela\":\"NAE\",\n",
    "        \"que asiste a la escuela\":\"AE\",\n",
    "        \n",
    "\n",
    "        \"que sabe leer y escribir\":\"SLE\",\n",
    "        \"que saben leer y escribir\":\"SLE\",\n",
    "        \"que no sabe leer y escribir\":\"NSLE\",\n",
    "        \"que no saben leer y escribir\":\"NSLE\",\n",
    "        \" alfabeta\":\"ABT\",\n",
    "        \"analfabeta\":\"ANBT\",\n",
    "\n",
    "        \"sin escolaridad\":\"SIN_E\",\n",
    "        \"primaria completa\":\"PRIM_COM\",\n",
    "        \"con instrucción media superior\":\"PREPA\",\n",
    "        \"con instrucción superior\":\"CARRERA\",\n",
    "        \"con instrucción posprimaria\":\"POS_PRIM\",\n",
    "        \"sin instrucción posprimaria\":\"SIN_POS_PRIM\",\n",
    "        \"sin instrucción\":\"KINDER\",\n",
    "        \"primaria incompleta\":\"PRIM_INC\",\n",
    "        \"secundaria completa\":\"SEC_COM\",\n",
    "        \"educación básica completa\":\"SEC_COM\",\n",
    "        \"secundaria incompleta\":\"SEC_INC\",\n",
    "        \"educación básica incompleta\":\"SEC_INC\",\n",
    "        \"educación pos-básica\":\"POSBASICA\",\n",
    "        \"educación posbásica\":\"POSBASICA\",\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Financial\n",
    "        \"más económicamente activa\":\"EC_ACTIVA\",\n",
    "        \"no económicamente activa\":\"NO_EC_ACTIVA\",\n",
    "        \" ocupada\":\"EMPLEADA\",\n",
    "        \"desocupada\":\"DESEMPLEADA\"\n",
    "\n",
    "\n",
    "    }\n",
    "    for replacement,category in categories.items():\n",
    "        match=re.search(fr'{replacement}',column_name)\n",
    "        if match:\n",
    "            return category\n",
    "    #print(\"No matches :( \")\n",
    "\n",
    "\n",
    "def grade(column_name):\n",
    "        match=re.search(\"Grado promedio\",column_name)\n",
    "        if match:\n",
    "            sex=re.search(\"femenina|masculina\",column_name)\n",
    "            if sex:\n",
    "                letter=str.upper(sex.group()[0])\n",
    "                return f\"GDO {letter}\"\n",
    "            return \"GDO\"\n",
    "        \n",
    "\n",
    "def other(column_name):\n",
    "        others={\n",
    "        #2020\n",
    "         'Clave de entidad federativa':'CVE_ENT',\n",
    "         'Entidad federativa':'ENT',\n",
    "         'Clave de municipio o demarcación territorial':'CVE TERR',\n",
    "         'Municipio o demarcación territorial':'MUN',\n",
    "         'Clave de localidad':'CVE_LOC',\n",
    "         'Clave de Localidad':'CVE_LOC',\n",
    "         'Localidad':'LOCALIDAD',\n",
    "         'Longitud':'LON',\n",
    "         'Latitud':'LAT',\n",
    "         'Altitud':'ALTI',\n",
    "         'Población total':'POB_TOT',\n",
    "         \n",
    "        #2010\n",
    "        'Clave de municipio ó delegación':'CVE TERR',\n",
    "        'Municipio ó delegación':'MUN',\n",
    "\n",
    "        #2005\n",
    "        'Entidad Federativa':'ENT',\n",
    "        \n",
    "        'Clave del Municipio':'CVE TERR',\n",
    "        'Municipio':'MUN',\n",
    "\n",
    "        #2000\n",
    "        'Nombre de la entidad':'ENT',\n",
    "        'Clave de municipio o delegación':'CVE TERR',\n",
    "        'Nombre del municipio o delegación':'MUN',\n",
    "        'Nombre de la localidad':'LOCALIDAD',\n",
    "\n",
    "        # Exceptions\n",
    "        'Población de cero a 14 años':'POB_0 a 14',\n",
    "        'Po blación femenina de 15 a 49 años':'POB_15 a 49'\n",
    "          }\n",
    "        \n",
    "\n",
    "\n",
    "        for replacement,other in others.items():\n",
    "            match=re.search(fr'{replacement}',column_name)\n",
    "            if match:\n",
    "                return other\n",
    "            \n",
    "\n",
    "def rename_columns(df):\n",
    "        original_columns={}\n",
    "    \n",
    "        for column in df.columns:\n",
    "\n",
    "            # Other columns:\n",
    "            if other(column):\n",
    "                original_columns[column]=other(column)\n",
    "                continue\n",
    "\n",
    "            # Population columns\n",
    "            if population(column):\n",
    "                if age_range(column):\n",
    "                    if category(column):\n",
    "                        #print(column, f\"{population(column)}_{age_range(column)}_{category(column)}\")\n",
    "                        original_columns[column]=f\"{population(column)}_{age_range(column)}_{category(column)}\"\n",
    "                        continue\n",
    "            \n",
    "                    #print(column, f\"{population(column)}_{age_range(column)}\")\n",
    "                    original_columns[column]=f\"{population(column)}_{age_range(column)}\"\n",
    "                    continue\n",
    "\n",
    "                #print(column, f\"{population(column)}\")\n",
    "                original_columns[column]=f\"{population(column)}\"\n",
    "                continue\n",
    "\n",
    "            # Grade Columns\n",
    "            if grade(column):\n",
    "                original_columns[column]=f\"{grade(column)}\"\n",
    "                #print(column,f\"{grade(column)}\")\n",
    "                continue\n",
    "            \n",
    "        \n",
    "        df=df.rename(columns=original_columns)\n",
    "            \n",
    "        return df,original_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CVE_ENT</th>\n",
       "      <th>ENT</th>\n",
       "      <th>CVE TERR</th>\n",
       "      <th>MUN</th>\n",
       "      <th>CVE_LOC</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>ALTI</th>\n",
       "      <th>...</th>\n",
       "      <th>POB M_12+_EC_ACTIVA</th>\n",
       "      <th>POB_12+_EC_ACTIVA</th>\n",
       "      <th>POB F_12+_EC_ACTIVA</th>\n",
       "      <th>POB M_12+_EC_ACTIVA</th>\n",
       "      <th>POB_12+_EMPLEADA</th>\n",
       "      <th>POB F_12+_EMPLEADA</th>\n",
       "      <th>POB M_12+_EMPLEADA</th>\n",
       "      <th>POB_12+_DESEMPLEADA</th>\n",
       "      <th>POB F_12+_DESEMPLEADA</th>\n",
       "      <th>POB M_12+_DESEMPLEADA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Total nacional</td>\n",
       "      <td>0</td>\n",
       "      <td>Total nacional</td>\n",
       "      <td>0</td>\n",
       "      <td>Total nacional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36815941</td>\n",
       "      <td>37891261</td>\n",
       "      <td>26379060</td>\n",
       "      <td>11512201</td>\n",
       "      <td>61121324</td>\n",
       "      <td>25137019</td>\n",
       "      <td>35984305</td>\n",
       "      <td>1160310</td>\n",
       "      <td>328674</td>\n",
       "      <td>831636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Total nacional</td>\n",
       "      <td>0</td>\n",
       "      <td>Total nacional</td>\n",
       "      <td>9998</td>\n",
       "      <td>Localidades de una vivienda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>95222</td>\n",
       "      <td>68766</td>\n",
       "      <td>42827</td>\n",
       "      <td>25939</td>\n",
       "      <td>127469</td>\n",
       "      <td>32906</td>\n",
       "      <td>94563</td>\n",
       "      <td>820</td>\n",
       "      <td>161</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Total nacional</td>\n",
       "      <td>0</td>\n",
       "      <td>Total nacional</td>\n",
       "      <td>9999</td>\n",
       "      <td>Localidades de dos viviendas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50429</td>\n",
       "      <td>46162</td>\n",
       "      <td>28959</td>\n",
       "      <td>17203</td>\n",
       "      <td>68215</td>\n",
       "      <td>18365</td>\n",
       "      <td>49850</td>\n",
       "      <td>689</td>\n",
       "      <td>110</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  CVE_ENT             ENT  CVE TERR             MUN  CVE_LOC  \\\n",
       "0           0        0  Total nacional         0  Total nacional        0   \n",
       "1           1        0  Total nacional         0  Total nacional     9998   \n",
       "2           2        0  Total nacional         0  Total nacional     9999   \n",
       "\n",
       "                      LOCALIDAD  LON  LAT ALTI  ...  POB M_12+_EC_ACTIVA  \\\n",
       "0                Total nacional  NaN  NaN  NaN  ...             36815941   \n",
       "1   Localidades de una vivienda  NaN  NaN  NaN  ...                95222   \n",
       "2  Localidades de dos viviendas  NaN  NaN  NaN  ...                50429   \n",
       "\n",
       "   POB_12+_EC_ACTIVA  POB F_12+_EC_ACTIVA  POB M_12+_EC_ACTIVA  \\\n",
       "0           37891261             26379060             11512201   \n",
       "1              68766                42827                25939   \n",
       "2              46162                28959                17203   \n",
       "\n",
       "   POB_12+_EMPLEADA  POB F_12+_EMPLEADA  POB M_12+_EMPLEADA  \\\n",
       "0          61121324            25137019            35984305   \n",
       "1            127469               32906               94563   \n",
       "2             68215               18365               49850   \n",
       "\n",
       "   POB_12+_DESEMPLEADA  POB F_12+_DESEMPLEADA  POB M_12+_DESEMPLEADA  \n",
       "0              1160310                 328674                 831636  \n",
       "1                  820                    161                    659  \n",
       "2                  689                    110                    579  \n",
       "\n",
       "[3 rows x 171 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_columns(df_2020)[0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rename_columns(df):\n",
    "    \"\"\" \n",
    "    This function takes a dataframe and checks if there are columns with the same name after renaming them using the 'rename_columns' function.\n",
    "    It spits out columns that don't have a unique name after being renamed.\n",
    "    \"\"\"\n",
    "    \n",
    "    problem_original=[]\n",
    "    problem_renamed=[]\n",
    "    column_dictionary=rename_columns(df)[1]\n",
    "\n",
    "\n",
    "    # Original Columns\n",
    "    original_column_list=column_dictionary.keys()\n",
    "    unique_original_columns=set(original_column_list)\n",
    "    not_unique_original=len(unique_original_columns)!=len(original_column_list) \n",
    "   \n",
    "    if not_unique_original:\n",
    "        for column in original_column_list:\n",
    "            if original_column_list.count(column) > 1 and column not in problem_original:\n",
    "                problem_original.append(column)\n",
    "\n",
    "\n",
    "    # Renamed Columns\n",
    "    renamed_column_list=list(column_dictionary.values())\n",
    "    unique_renamed_columns=set(renamed_column_list)\n",
    "    not_unique_renamed=len(unique_renamed_columns)!=len(renamed_column_list)\n",
    "\n",
    "    if not_unique_renamed:\n",
    "        for original_column,renamed_column in column_dictionary.items():\n",
    "            if renamed_column_list.count(renamed_column) > 1 and (original_column,renamed_column) not in problem_renamed:\n",
    "                problem_renamed.append((original_column,renamed_column))\n",
    "\n",
    "    \n",
    "    return (problem_original,problem_renamed)\n",
    "\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rename_columns(filter(df_2020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rename_columns(filter(df_2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rename_columns(filter(df_2005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rename_columns(filter(df_2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have a good function to rename my variables, all we need now is to filter the columns we aren't interested in,(again): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(df):\n",
    "    \n",
    "    columns_staying=[]\n",
    "    columns_to_filter_out=[\n",
    "        'Relación hombres-mujeres',\n",
    "        'Población de 15 años y más con instrucción secundaria o estudios técnicos o comerciales con primaria terminada',\n",
    "        # Disabilities\n",
    "        'Población con discapacidad', \n",
    "        'Población con discapacidad para hablar o comunicarse', \n",
    "        'Población con discapacidad para oír, aun usando aparato auditivo', \n",
    "        'Población con discapacidad para vestirse, bañarse o comer', \n",
    "        'Población con discapacidad para recordar o concentrarse', \n",
    "        'Población con limitación', \n",
    "        'Población con limitación para caminar, subir o bajar', \n",
    "        'Población con limitación para ver, aun usando lentes', \n",
    "        'Población con limitación para hablar o comunicarse', \n",
    "        'Población con limitación para oír, aun usando aparato auditivo', \n",
    "        'Población con limitación para vestirse, bañarse o comer', \n",
    "        'Población con limitación para recordar o concentrarse', \n",
    "        'Población con algún problema o condición mental', \n",
    "        'Población sin discapacidad, limitación, problema o condición mental',\n",
    "\n",
    "        'Población con limitación en la actividad',\n",
    "        'Población con limitación para caminar o moverse, subir o bajar',\n",
    "        'Población con limitación para ver, aún usando lentes',\n",
    "        'Población con limitación para hablar, comunicarse o conversar',\n",
    "        'Población con limitación para escuchar',\n",
    "        'Población con limitación para poner atención o aprender cosas sencillas',\n",
    "        'Población con limitación mental',\n",
    "        'Población sin limitación en la actividad',\n",
    "        # Financial\n",
    "        \n",
    "       'Población de 12 años y más económicamente activa',\n",
    "       'Población femenina de 12 años y más económicamente activa',\n",
    "       'Población masculina de 12 años y más económicamente activa',\n",
    "       'Población de 12 años y más no económicamente activa',\n",
    "       'Población femenina de 12 años y más no económicamente activa',\n",
    "       'Población masculina de 12 años y más no económicamente activa',\n",
    "       'Población de 12 años y más ocupada',\n",
    "       'Población femenina de 12 años y más ocupada',\n",
    "       'Población masculina de 12 años y más ocupada',\n",
    "       'Población de 12 años y más desocupada',\n",
    "       'Población femenina de 12 años y más desocupada',\n",
    "       'Población masculina de 12 años y más desocupada'\n",
    "       ]\n",
    "    \n",
    "    for column in df.columns:\n",
    "\n",
    "        if column in columns_to_filter_out:\n",
    "            continue\n",
    "\n",
    "        columns_staying.append(column)\n",
    "\n",
    "    filtered_df=df[columns_staying]\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the hard part: concatenating these bad boys. What we can simply do is stack one dataset over the other, and fill the variables that one doesn't have with the population value of the year plus 666, to know they come from this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_dfs=[]\n",
    "dataframes=[df_2020, df_2010, df_2005, df_2000]\n",
    "for df in dataframes:\n",
    "    filtered_df=filter(df)\n",
    "    renamed_df=rename_columns(filtered_df)[0]\n",
    "    renamed_dfs.append(renamed_df)\n",
    "    \n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joining(dataframes):\n",
    "    \"\"\" \n",
    "    This function takes a list of dataframes, adds missing columns to each dataframe, based on the dataframe with the most columns\n",
    "    \"\"\"\n",
    "    reference_df=max(dataframes,key=lambda df: len(df.columns))\n",
    "    reference_columns=reference_df.columns\n",
    "    for df in dataframes:\n",
    "        for column in reference_columns:\n",
    "            if column not in df.columns:\n",
    "                data_type=reference_df[column].dtype\n",
    "                print(data_type)\n",
    "                #df[column]=\n",
    "    #dataset=pd.concat()\n",
    "    #return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        list\n",
      "\u001b[0;31mString form:\u001b[0m\n",
      "[        Unnamed: 0  CVE_ENT             ENT  CVE TERR  \\\n",
      "           0                0        0  Total naci <...>               0  3.0\n",
      "           112861              0                0  3.0\n",
      "           \n",
      "           [112862 rows x 47 columns]]\n",
      "\u001b[0;31mLength:\u001b[0m      4\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "Built-in mutable sequence.\n",
      "\n",
      "If no argument is given, the constructor creates a new empty list.\n",
      "The argument must be an iterable if specified."
     ]
    }
   ],
   "source": [
    "renamed_dfs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_keys' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[416], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjoining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenamed_dfs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[413], line 11\u001b[0m, in \u001b[0;36mjoining\u001b[0;34m(dataframes)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m column \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     10\u001b[0m     data_type\u001b[38;5;241m=\u001b[39mreference_df[column]\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_keys' object is not callable"
     ]
    }
   ],
   "source": [
    "joining(renamed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
